{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Portfolio Optimization using cvxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install cvxpy and other libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/jason/.pyenv/versions/3.6.10/lib/python3.6/site-packages (1.14.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import quiz_tests_advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's our objective?\n",
    "http://www.cvxpy.org/\n",
    "\n",
    "Let's see how we can use optimization to meet a more advanced objective.  We want to both minimize the portfolio variance and also want to closely track a market cap weighted index.  In other words, we're trying to minimize the distance between the weights of our portfolio and the weights of the index.\n",
    "\n",
    "$Minimize \\left [ \\sigma^2_p + \\lambda \\sqrt{\\sum_{1}^{m}(weight_i - indexWeight_i)^2} \\right  ]$ where $m$ is the number of stocks in the portfolio, and $\\lambda$ is a scaling factor that you can choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "### x vector\n",
    "To create a vector of M variables $\\mathbf{x} = \\begin{bmatrix}\n",
    "x_1 &...& x_M\n",
    "\\end{bmatrix}\n",
    "$\n",
    "we can use `cvx.Variable(m)`\n",
    "\n",
    "### covariance matrix\n",
    "If we have $m$ stock series, the covariance matrix is an $m \\times m$ matrix containing the covariance between each pair of stocks.  We can use [numpy.cov](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html) to get the covariance.  We give it a 2D array in which each row is a stock series, and each column is an observation at the same period of time.\n",
    "\n",
    "The covariance matrix $\\mathbf{P} = \n",
    "\\begin{bmatrix}\n",
    "\\sigma^2_{1,1} & ... & \\sigma^2_{1,m} \\\\ \n",
    "... & ... & ...\\\\\n",
    "\\sigma_{m,1} & ... & \\sigma^2_{m,m}  \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portfolio variance\n",
    "We can write the portfolio variance $\\sigma^2_p = \\mathbf{x^T} \\mathbf{P} \\mathbf{x}$\n",
    "\n",
    "Recall that the $\\mathbf{x^T} \\mathbf{P} \\mathbf{x}$ is called the quadratic form.\n",
    "We can use the cvxpy function `quad_form(x,P)` to get the quadratic form.\n",
    "\n",
    "### Distance from index weights\n",
    "We want portfolio weights that track the index closely.  So we want to minimize the distance between them.\n",
    "Recall from the Pythagorean theorem that you can get the distance between two points in an x,y plane by adding the square of the x and y distances and taking the square root.  Extending this to any number of dimensions is called the L2 norm.  So: $\\sqrt{\\sum_{1}^{n}(weight_i - indexWeight_i)^2}$  Can also be written as $\\left \\| \\mathbf{x} - \\mathbf{index} \\right \\|_2$.  There's a cvxpy function called [norm()](https://www.cvxpy.org/api_reference/cvxpy.atoms.other_atoms.html#norm)\n",
    "`norm(x, p=2, axis=None)`.  The default is already set to find an L2 norm, so you would pass in one argument, which is the difference between your portfolio weights and the index weights.\n",
    "\n",
    "### objective function\n",
    "We want to minimize both the portfolio variance and the distance of the portfolio weights from the index weights.\n",
    "We also want to choose a `scale` constant, which is $\\lambda$ in the expression. This lets us choose how much priority we give to minimizing the difference from the index, relative to minimizing the variance of the portfolio.  If you choose a higher value for `scale` ($\\lambda$), do you think this gives more priority to minimizing the difference, or minimizing the variance?\n",
    "\n",
    "We can find the objective function using cvxpy `objective = cvx.Minimize()`.  Can you guess what to pass into this function?\n",
    "\n",
    "### constraints\n",
    "We can also define our constraints in a list.  For example, you'd want the weights to sum to one. So $\\sum_{1}^{n}x = 1$.  You may also need to go long only, which means no shorting, so no negative weights.  So $x_i >0 $ for all $i$. you could save a variable as `[x >= 0, sum(x) == 1]`, where x was created using `cvx.Variable()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization\n",
    "So now that we have our objective function and constraints, we can solve for the values of $\\mathbf{x}$.\n",
    "cvxpy has the constructor `Problem(objective, constraints)`, which returns a `Problem` object.\n",
    "\n",
    "The `Problem` object has a function solve(), which returns the minimum of the solution.  In this case, this is the minimum variance of the portfolio.\n",
    "\n",
    "It also updates the vector $\\mathbf{x}$.\n",
    "\n",
    "We can check out the values of $x_A$ and $x_B$ that gave the minimum portfolio variance by using `x.value`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43114169  0.08694532  0.48858726 -0.07017734  0.2044459   0.24149525\n",
      "   0.12789726 -0.07745882 -0.07954606 -0.46043708  0.52696829 -0.44613704\n",
      "  -0.00318947  0.01832415  0.11106734  0.31723196 -0.15139174 -0.01088555\n",
      "   0.30624232 -0.23968901  0.22534855 -0.55800461 -0.37435844 -0.23726753\n",
      "   0.26123958 -0.13780188 -0.36884133  0.2592158  -0.35850128 -0.00282834\n",
      "  -0.62996011 -0.31066603  0.00446988  0.5089494  -0.05992667 -0.52264191\n",
      "   0.5168536   0.23943927 -0.36325465 -0.04901924  0.39803562  0.42396098\n",
      "   0.3571138   0.41129433 -0.47947148  0.72652888  0.22604963  0.10097998\n",
      "  -0.1238279   0.02162088  0.57507527 -0.15969482  0.41587091  0.97724204\n",
      "  -0.04089145  0.00339871 -0.1163075   0.61341308  0.68333986  0.30891983\n",
      "   0.13455914  0.09632899  0.35214768 -0.14745189 -0.53735404  0.29356529\n",
      "  -0.12745912 -0.01675288  0.56359723 -0.59026381 -0.23222344 -0.27974108\n",
      "   0.01483703  0.11780301 -0.1127267   0.03250582  0.36394626 -0.2070217\n",
      "   0.71383349  0.05197158  0.73852352 -0.14325131  0.16862405  0.13018119\n",
      "   0.25280547  0.06382061  0.32750356 -0.63652913  0.49192797  0.02398298\n",
      "  -0.07424808  0.28667991 -0.31216282  0.5825416   0.46372785  0.3482738\n",
      "   0.43093514 -0.44825024 -0.16049096  0.09118743  0.07565607 -0.08470177\n",
      "  -0.10977015  0.44705605  0.00691606 -0.27136748 -0.55233981 -0.17471796\n",
      "  -0.01142854  0.03807372  0.01967879  0.38354796 -0.04678073 -0.1266102\n",
      "  -0.65375086  0.32831341  0.16406775  0.05813021  0.44908333 -0.22595623\n",
      "  -0.27963434  0.33835897  0.19581304 -0.0091869   0.01093333  0.12452585\n",
      "   0.08523376 -0.06055448  0.44498394  0.25714885  0.19312046  0.0744136\n",
      "  -0.42008769 -0.04355916 -0.2914536  -0.09033171 -0.0251868  -0.06252355\n",
      "  -0.00155793  0.03834331 -0.47044922  0.21320517 -0.57908086 -0.23784545\n",
      "  -0.46441104  0.54553269  0.08560932 -0.13471435 -0.02409403  0.24720448\n",
      "   0.25066656 -0.25758721  0.415136    0.21213318 -0.20110337 -0.42242872\n",
      "   0.30039006  0.28862852 -0.28560582  0.15073193  0.08621814  0.10734463\n",
      "   0.39552744  0.03846024  0.08642962  0.22631401  0.29928374 -0.34821799\n",
      "   0.34056592 -0.53898496  0.2664444   0.21171883  0.19130892  0.42413456\n",
      "  -0.46063895 -0.11732693 -0.09139309 -0.30004076 -0.18195085 -0.10800613\n",
      "   0.07711052  0.02964387  0.65690536  0.13831802 -0.12729572 -0.54580759\n",
      "   0.15661588  0.02677422 -0.06172798  0.89674303 -0.46356554 -0.24934001\n",
      "   0.0963613  -0.50911698 -0.00373928  0.27880259 -0.40913802  0.49794539\n",
      "   0.03054086  0.01872574  0.9398263   0.16283224 -0.00277667 -0.01594289\n",
      "  -0.10697479  0.30333504 -0.09229463  0.36355343 -0.19541087 -0.05387867\n",
      "   0.16777824 -0.2194844  -0.52863867  0.29025253 -0.10582026  0.04427728\n",
      "   0.33089176  0.17813848  0.22380191  0.2614915  -0.11903453 -0.59277884\n",
      "  -0.08892738  0.24255355 -0.38010899 -0.26863183  0.05032109 -0.15570445\n",
      "   0.08416496  0.04044117 -0.2540266   0.90905784  0.0208494  -0.08547472\n",
      "  -0.2738736   0.50406136  0.09932786  0.44145924  0.37676293  0.39423265\n",
      "   0.21690932  0.18129157  0.32139654 -0.00903315  0.17377416  0.38139145\n",
      "  -0.17659995 -0.05686659  0.51527875 -0.02943796  0.48855294 -0.10855593]\n",
      " [ 0.43114169  0.08694635  0.48858763 -0.07017768  0.20444633  0.24149621\n",
      "   0.12789702 -0.07745922 -0.07954563 -0.46043688  0.52696812 -0.44613552\n",
      "  -0.00318765  0.01832429  0.11106796  0.3172308  -0.15139207 -0.01088441\n",
      "   0.30624373 -0.23968934  0.22534792 -0.55800591 -0.374358   -0.23726788\n",
      "   0.26123837 -0.13780111 -0.36884161  0.25921555 -0.3585015  -0.00282932\n",
      "  -0.62996175 -0.31066579  0.00447006  0.5089487  -0.05992645 -0.52264231\n",
      "   0.51685343  0.23944069 -0.36325384 -0.04901904  0.39803621  0.4239607\n",
      "   0.35711308  0.41129338 -0.47947113  0.72652811  0.22604969  0.1009796\n",
      "  -0.12382771  0.02162201  0.57507483 -0.15969471  0.41587181  0.97724226\n",
      "  -0.04089176  0.00340021 -0.1163066   0.61341367  0.68333986  0.30891805\n",
      "   0.13455821  0.09632959  0.3521462  -0.14745171 -0.53735371  0.29356385\n",
      "  -0.1274605  -0.01675433  0.56359669 -0.59026336 -0.23222259 -0.27974278\n",
      "   0.01483687  0.11780188 -0.11272495  0.0325041   0.3639473  -0.20702194\n",
      "   0.71383408  0.05197114  0.73852222 -0.14324973  0.16862525  0.13018222\n",
      "   0.25280558  0.06382017  0.32750264 -0.63652911  0.49192759  0.02398357\n",
      "  -0.07424838  0.28667871 -0.3121621   0.58254003  0.46372747  0.34827384\n",
      "   0.43093361 -0.44824957 -0.16049117  0.09118795  0.0756557  -0.08470276\n",
      "  -0.10977049  0.44705729  0.00691642 -0.27136833 -0.55234014 -0.17471878\n",
      "  -0.01142671  0.03807363  0.01967769  0.38354851 -0.04678217 -0.12661023\n",
      "  -0.65375005  0.32831328  0.16406773  0.05813198  0.44908287 -0.22595637\n",
      "  -0.27963526  0.33835876  0.19581325 -0.00918713  0.01093417  0.12452707\n",
      "   0.08523332 -0.06055528  0.44498469  0.2571499   0.19312166  0.0744154\n",
      "  -0.42008916 -0.04355897 -0.29145446 -0.09033284 -0.0251868  -0.0625244\n",
      "  -0.00155768  0.03834263 -0.47045049  0.21320509 -0.57908022 -0.23784624\n",
      "  -0.4644119   0.54553357  0.08560976 -0.13471275 -0.02409305  0.24720498\n",
      "   0.25066739 -0.25758707  0.41513618  0.21213476 -0.20110392 -0.42242997\n",
      "   0.30039089  0.28863024 -0.28560512  0.15073012  0.08621729  0.10734576\n",
      "   0.39552849  0.03845921  0.08642955  0.22631504  0.29928473 -0.34821827\n",
      "   0.3405666  -0.5389854   0.2664443   0.21171863  0.19130893  0.42413361\n",
      "  -0.46063828 -0.11732843 -0.091394   -0.30004152 -0.18195073 -0.1080061\n",
      "   0.07711004  0.02964523  0.65690456  0.13831649 -0.12729594 -0.54580713\n",
      "   0.15661627  0.02677486 -0.06172726  0.89674298 -0.46356633 -0.24934075\n",
      "   0.0963618  -0.50911708 -0.00374001  0.27880234 -0.40913905  0.49794503\n",
      "   0.0305407   0.0187268   0.9398259   0.16283299 -0.0027766  -0.01594414\n",
      "  -0.10697429  0.30333511 -0.09229434  0.36355325 -0.19541039 -0.05387857\n",
      "   0.16777806 -0.21948429 -0.52863764  0.29025241 -0.10581984  0.04427671\n",
      "   0.33089178  0.17813812  0.22380184  0.26149117 -0.11903426 -0.59278032\n",
      "  -0.08892723  0.24255284 -0.3801093  -0.26863097  0.0503194  -0.15570445\n",
      "   0.08416459  0.0404401  -0.2540259   0.90905793  0.02084981 -0.08547458\n",
      "  -0.27387315  0.50406221  0.099327    0.441458    0.37676341  0.39423305\n",
      "   0.21690953  0.18129119  0.3213958  -0.00903339  0.17377579  0.38139265\n",
      "  -0.17659986 -0.05686696  0.51527828 -0.02943886  0.4885538  -0.10855542]\n",
      " [ 0.43114127  0.08694625  0.48858635 -0.0701776   0.20444579  0.24149542\n",
      "   0.12789688 -0.07745959 -0.07954635 -0.46043701  0.526968   -0.4461358\n",
      "  -0.0031881   0.01832536  0.11106809  0.31723115 -0.15139199 -0.01088419\n",
      "   0.30624296 -0.23969046  0.22534865 -0.55800463 -0.37435837 -0.2372679\n",
      "   0.26123981 -0.13780132 -0.36884218  0.25921664 -0.35850189 -0.00282784\n",
      "  -0.62996182 -0.31066438  0.00446935  0.50894973 -0.05992694 -0.52264248\n",
      "   0.51685205  0.23943933 -0.36325489 -0.04901829  0.39803713  0.42396112\n",
      "   0.35711367  0.4112947  -0.47947151  0.72652911  0.22604839  0.10097977\n",
      "  -0.12382828  0.0216208   0.57507552 -0.15969546  0.41587191  0.97724285\n",
      "  -0.04089252  0.00339931 -0.11630597  0.61341422  0.68334041  0.30891945\n",
      "   0.13455962  0.0963307   0.35214661 -0.14745259 -0.53735456  0.29356402\n",
      "  -0.12745948 -0.01675283  0.56359611 -0.5902637  -0.23222345 -0.27974306\n",
      "   0.01483642  0.11780267 -0.11272645  0.03250501  0.36394673 -0.20702099\n",
      "   0.71383285  0.0519722   0.73852236 -0.14325035  0.16862554  0.13018117\n",
      "   0.25280609  0.06382003  0.32750245 -0.63652938  0.49192851  0.02398311\n",
      "  -0.07424751  0.28667942 -0.31216182  0.58254079  0.46372756  0.34827423\n",
      "   0.43093467 -0.44824839 -0.16049103  0.09118724  0.07565741 -0.08470225\n",
      "  -0.10977114  0.44705551  0.00691602 -0.27136676 -0.55234055 -0.17471943\n",
      "  -0.01142699  0.03807438  0.01967713  0.38354707 -0.04678067 -0.12660952\n",
      "  -0.65375015  0.32831285  0.16406734  0.05813097  0.44908322 -0.225956\n",
      "  -0.279634    0.33835886  0.19581252 -0.0091868   0.01093357  0.12452716\n",
      "   0.0852341  -0.06055556  0.44498428  0.2571497   0.19312212  0.07441467\n",
      "  -0.42008829 -0.04355836 -0.29145487 -0.09033238 -0.02518762 -0.06252412\n",
      "  -0.00155844  0.03834212 -0.47045075  0.21320514 -0.57908151 -0.23784619\n",
      "  -0.46441196  0.54553347  0.08560971 -0.13471331 -0.02409439  0.24720396\n",
      "   0.25066698 -0.25758689  0.41513579  0.21213366 -0.20110313 -0.42242936\n",
      "   0.30038929  0.28862906 -0.28560553  0.15073186  0.08621834  0.10734634\n",
      "   0.39552888  0.03845917  0.08642985  0.22631524  0.2992843  -0.34821705\n",
      "   0.34056555 -0.53898635  0.26644474  0.21171804  0.19131043  0.42413415\n",
      "  -0.46063758 -0.11732801 -0.09139344 -0.30004096 -0.18195112 -0.10800687\n",
      "   0.0771108   0.02964404  0.65690506  0.13831816 -0.12729593 -0.54580744\n",
      "   0.1566162   0.0267758  -0.06172873  0.89674237 -0.46356533 -0.24934125\n",
      "   0.09636286 -0.50911613 -0.00374024  0.27880239 -0.40913819  0.49794548\n",
      "   0.03054044  0.01872644  0.93982649  0.16283272 -0.00277726 -0.01594269\n",
      "  -0.10697431  0.30333517 -0.09229618  0.36355356 -0.19540942 -0.05387916\n",
      "   0.16777805 -0.21948279 -0.52863855  0.29025435 -0.10582119  0.04427723\n",
      "   0.330891    0.17813872  0.22380109  0.26149061 -0.11903503 -0.59277885\n",
      "  -0.08892726  0.24255275 -0.3801088  -0.26863046  0.05031997 -0.15570502\n",
      "   0.08416463  0.04044173 -0.25402661  0.90905755  0.02084898 -0.08547532\n",
      "  -0.27387372  0.5040609   0.09932665  0.44145921  0.37676268  0.39423169\n",
      "   0.21690934  0.18129237  0.32139513 -0.00903293  0.17377522  0.38139164\n",
      "  -0.17659901 -0.05686757  0.51527787 -0.02943878  0.48855378 -0.1085554 ]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "\n",
    "def optimize_portfolio(returns, index_weights, scale=.00001):\n",
    "    \"\"\"\n",
    "    Create a function that takes the return series of a set of stocks, the index weights,\n",
    "    and scaling factor. The function will minimize a combination of the portfolio variance\n",
    "    and the distance of its weights from the index weights.  \n",
    "    The optimization will be constrained to be long only, and the weights should sum to one.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : numpy.ndarray\n",
    "        2D array containing stock return series in each row.\n",
    "        \n",
    "    index_weights : numpy.ndarray\n",
    "        1D numpy array containing weights of the index.\n",
    "        \n",
    "    scale : float\n",
    "        The scaling factor applied to the distance between portfolio and index weights\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        A numpy ndarray containing the weights of the stocks in the optimized portfolio\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of stocks\n",
    "    m = returns.shape[0]\n",
    "    \n",
    "    # covariance between stocks \n",
    "    cov = np.cov(returns)\n",
    "    \n",
    "    # settingup cvx variable\n",
    "    x = cvx.Variable(m)\n",
    "    \n",
    "    # in quadratic form\n",
    "    quadP = cvx.quad_form(x,cov)\n",
    "    \n",
    "    # l2 normal for distances from weights\n",
    "    norm = cvx.norm(x - index_weights)\n",
    "    \n",
    "    # objective is to min variance and scaled stay close to index\n",
    "    objective = cvx.Minimize(quadP + scale * norm)\n",
    "\n",
    "    # constraints, not allowed to short, must use all portfolio\n",
    "    constraints = [x >= 0, sum(x) ==1]\n",
    "    \n",
    "    # minimize the function \n",
    "    cvx.Problem(objective,constraints).solve()\n",
    "    \n",
    "    x_vals = x.value\n",
    "    return x_vals\n",
    "        \n",
    "\n",
    "quiz_tests_advanced.test_optimize_portfolio(optimize_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimized weights are [0.86747089 0.1164104  0.01611871], which sum to 1.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test with a 3 simulated stock return series\"\"\"\n",
    "days_per_year = 252\n",
    "years = 3\n",
    "total_days = days_per_year * years\n",
    "\n",
    "return_market = np.random.normal(loc=0.05, scale=0.3, size=days_per_year)\n",
    "return_1 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_2 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "return_3 = np.random.uniform(low=-0.000001, high=.000001, size=days_per_year) + return_market\n",
    "returns = np.array([return_1, return_2, return_3])\n",
    "\n",
    "\"\"\"simulate index weights\"\"\"\n",
    "index_weights = np.array([0.9,0.15,0.05])\n",
    "\n",
    "\"\"\"try out your optimization function\"\"\"\n",
    "x_values = optimize_portfolio(returns, index_weights, scale=.00001)\n",
    "\n",
    "print(f\"The optimized weights are {x_values}, which sum to {sum(x_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're feeling stuck, you can check out the solution [here](m3l4_cvxpy_advanced_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
